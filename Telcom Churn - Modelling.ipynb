{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For this churn problem - the data is being loaded from https://www.kaggle.com/blastchar/telco-customer-churn\n",
    "\n",
    "file = '../WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "\n",
    "churn_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data.columns = [col.title() for col in churn_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customerid', 'Gender', 'Seniorcitizen', 'Partner', 'Dependents',\n",
       "       'Tenure', 'Phoneservice', 'Multiplelines', 'Internetservice',\n",
       "       'Onlinesecurity', 'Onlinebackup', 'Deviceprotection', 'Techsupport',\n",
       "       'Streamingtv', 'Streamingmovies', 'Contract', 'Paperlessbilling',\n",
       "       'Paymentmethod', 'Monthlycharges', 'Totalcharges', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline is going to be randomly assigning a class - 0/1 for No churn/Churn respectively\n",
    "\n",
    "I am selecting three models here - linear regression for its class probability estimations, knn as it based on distances and random forest for its entropy. We can later make ensemble models combining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customerid            object\n",
       "Gender              category\n",
       "Seniorcitizen       category\n",
       "Partner             category\n",
       "Dependents          category\n",
       "Tenure                 int64\n",
       "Phoneservice        category\n",
       "Multiplelines       category\n",
       "Internetservice     category\n",
       "Onlinesecurity      category\n",
       "Onlinebackup        category\n",
       "Deviceprotection    category\n",
       "Techsupport         category\n",
       "Streamingtv         category\n",
       "Streamingmovies     category\n",
       "Contract            category\n",
       "Paperlessbilling    category\n",
       "Paymentmethod       category\n",
       "Monthlycharges       float64\n",
       "Totalcharges         float64\n",
       "Churn               category\n",
       "dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reengineering some features to reduce the distance issues with some classification models.\n",
    "churn_data['Tenure_in_yrs'] = churn_data['Tenure']//12\n",
    "churn_data['Monthlycharges_100s'] = round(churn_data['Monthlycharges']/100,2)\n",
    "churn_data['Totalcharges'] = pd.to_numeric(churn_data['Totalcharges'], errors='coerce').fillna(0)\n",
    "churn_data['Totalcharges_1000s'] = round(churn_data['Totalcharges']/1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'No Internet Service' and 'No Phone Service'  as No\n",
    "churn_data = churn_data.replace{'No phone service':'No', 'No internet service':'No'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_categorical_data(df, cols, drop_orgnl = True, drop_first=True, convert_ascat = True):\n",
    "    \"\"\"\n",
    "    Transform categorical data in the columns into dummy data using pandas.\n",
    "    ----------\n",
    "    df : Dataframe \n",
    "    cols : categorical columns to convert into.\n",
    "    drop_orgnl : Boolean, if set to True drops the original column.\n",
    "    drop_first : Boolean if True drops one of the dummy column\n",
    "    convert_ascat : convert columns into categorical.\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    Dataframe with the original frame concatenated with dummy data\n",
    "    \"\"\"\n",
    "\n",
    "    if convert_ascat == True:\n",
    "        df[cols] = df[cols].astype('category')\n",
    "    \n",
    "    dummy_data = pd.get_dummies(df[cols],prefix=cols,drop_first=drop_first)\n",
    "    #concatenate the dummy data and dataframe. Drop the original columns \n",
    "    \n",
    "    df_cat = pd.concat([df,dummy_data],axis=1)\n",
    "    if drop_orgnl == True:\n",
    "        df_cat.drop(columns=cols, inplace = True)\n",
    "    \n",
    "    return df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data_tf = transform_categorical_data(churn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a baseline predictor that randomly assigns a customer as churn or no churn\n",
    "def baseline_pred(X, y_true):\n",
    "    from numpy.random import rand, randint\n",
    "    y_pred = [randint(0,2) for i in range(X.shape[0])]\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred)\n",
    "    accuracy = round(tp/X.shape[0],3)\n",
    "    print('baseline accuracy is {}'.format(accuracy))    \n",
    "\n",
    "baseline_pred(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the metrics we want to use to compare for each model\n",
    "def classification_metrics(y_true, y_pred, model, y_prob, ret_results = True, print_res = True):\n",
    "    \"\"\"\n",
    "    Calculates different classification metrics for the model, and prints out the results\n",
    "    ----------\n",
    "    y_true : actual output values \n",
    "    y_pred : predicted values based on the model\n",
    "    model : Classification model with already training data fitted on the model\n",
    "    ret_results : To return different metrics as a dictionary\n",
    "    print_res : prints out the metrics as well as roc curve.\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    Returns a dictionary with different metrics if ret_results is set to True\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    #balanced accuracy score\n",
    "    from sklearn.metrics import balanced_accuracy_score, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "    acc = round(accuracy_score(y_true, y_pred),3)\n",
    "    bal_acc = round(balanced_accuracy_score(y_true, y_pred),3)\n",
    "    #sensitivity and specificity - identifiying churning customers more important than stable customers\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = round(tp/(tp+fn), 3)\n",
    "    specificity = round(tn/(tn+fp), 3)\n",
    "    \n",
    "    #auc score\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob[:,1])\n",
    "    auc_score = round(auc(fpr, tpr), 3)\n",
    "    res_dict = {'Accuracy':acc, 'Balanced acc':bal_acc, 'sensitivity': sensitivity, \n",
    "                'specificity':specificity, 'auc':auc_score}\n",
    "    \n",
    "    if print_res == True:\n",
    "        print(model)\n",
    "        print(res_dict)\n",
    "        \n",
    "        plt.grid()\n",
    "        plt.plot(fpr,tpr)\n",
    "        plt.fill_between(fpr, tpr, color = 'silver')\n",
    "        plt.annotate('Area under Curve {}'.format(auc_score), (0,0.9), fontsize = 10)\n",
    "        plt.title('ROC Curve')\n",
    "        plt.show()\n",
    "    \n",
    "    if ret_results == True:\n",
    "        return res_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to generalize this function with any model and its additional parameters\n",
    "\n",
    "\n",
    "def model_CVsplit_metrics(X, Y, model, size = 0.4, random_st = 16):\n",
    "    \"\"\"\n",
    "    Fits the classification model with a train test split and calculates and displays the metrics\n",
    "    ----------\n",
    "    X : input data set \n",
    "    Y : output labels \n",
    "    model : Classification model with parameters tuned.\n",
    "    size : Size of the test for the train_test_split\n",
    "    random_st : random state value\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    Returns the model with fitted data\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y , test_size=size, random_state = random_st)\n",
    "    \n",
    "    model = model.fit(X_train,y_train)\n",
    "    \n",
    "    test_score = model.score(X_test, y_test)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "       \n",
    "    print('test score {}'.format(test_score))\n",
    "    print('training score {}'.format(train_score))\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    classification_metrics(y_true = y_test, y_pred=y_hat, model=model, y_prob=y_proba, ret_results= False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = churn_data_tf.iloc[:, 1:-1], churn_data_tf.Churn_Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5, 7043]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-fa22803f93a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#applying logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_CVsplit_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-151-ecca280dabde>\u001b[0m in \u001b[0;36mmodel_CVsplit_metrics\u001b[0;34m(X, Y, model, size, random_st)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_st\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2096\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5, 7043]"
     ]
    }
   ],
   "source": [
    "#applying logistic regression\n",
    "logit = LogisticRegression(solver='liblinear')\n",
    "logit = model_CVsplit_metrics(X, Y, model= logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(weights='distance')\n",
    "knn_model = model_CVsplit_metrics(X,Y, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_forest = RandomForestClassifier()\n",
    "rnd_forest = model_CVsplit_metrics(X,Y,rnd_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
